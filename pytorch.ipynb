{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://pytorch.org/docs/stable/nn.html\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        \"\"\"\n",
    "        Initialize the wine dataset variables.\n",
    "        :param X: Features of shape [n, num_genes], where n is number of samples.\n",
    "        :param Y: Labels of shape [n], where n is number of samples.\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Dataset\", X.shape, Y.shape)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples.\n",
    "        :return: The number of samples.\n",
    "        \"\"\"\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns feature and label of the sample at the given index.\n",
    "        :param index: Index of a sample.\n",
    "        :return: Feature and label of the sample at the given index.\n",
    "        \"\"\"\n",
    "        return self.X[index], torch.Tensor([self.Y[index]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size, dataset_X ='processed_mrna_data.npy', dataset_Y = 'processed_recurrence_data.npy', test_size=0.2):\n",
    "    \"\"\"\n",
    "    Returns train/test dataloaders\n",
    "    :param dataset: Path dataset \n",
    "    :param test_size: Ratio of (test set size / dataset size)\n",
    "    :return: Dataloaders for training set and test set.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    \n",
    "    # Load the dataset\n",
    "    X = np.load(dataset_X)\n",
    "    Y = np.load(dataset_Y)\n",
    "\n",
    "    # Normalize the features\n",
    "    #X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "    # Convert to float32\n",
    "    X = X.astype(np.float32)\n",
    "    Y = Y.astype(np.float32)\n",
    "    # Split data into training set and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset_train = Data(X_train, Y_train)\n",
    "    dataset_test = Data(X_test, Y_test)\n",
    "\n",
    "    # Build dataloader\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return dataloader_train, dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayerNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features=20531):\n",
    "        \"\"\"\n",
    "        Initializes a liner layer.\n",
    "        :param input_features: The number of features of each sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Initialize a linear layer. HINT: torch.nn.Linear\n",
    "        self.layer = torch.nn.Linear(input_features, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Applies the linear layer defined in __init__() to input features X.\n",
    "        :param X: 2D torch tensor of shape [n, 11], where n is batch size.\n",
    "            Represents features of a batch of data.\n",
    "        :return: 2D torch tensor of shape [n, 1], where n is batch size.\n",
    "            Represents prediction of wine quality.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Apply the linear layer defined in __init__() to input features X\n",
    "        return self.layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features):\n",
    "        \"\"\"\n",
    "        Initializes model layers.\n",
    "        :param input_features: The number of features of each sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Tune the hidden size hyper-parameter\n",
    "        self.hidden_size = 200\n",
    "\n",
    "        # TODO: Initialize a linear layer. HINT: torch.nn.Linear\n",
    "        self.layer1 = torch.nn.Linear(input_features, self.hidden_size)\n",
    "    \n",
    "        # TODO: Initialize a sigmoid activation layer. HINT: torch.nn.Sigmoid\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        # TODO: Initialize another linear layer\n",
    "        self.layer2 = torch.nn.Linear(self.hidden_size, 20)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "\n",
    "        self.model = torch.nn.Sequential(self.layer1, self.activation, self.layer2)\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Applies the layers defined in __init__() to input features X.\n",
    "        :param X: 2D torch tensor of shape [n, 11], where n is batch size.\n",
    "            Represents features of a batch of data.\n",
    "        :return: 2D torch tensor of shape [n, 1], where n is batch size.\n",
    "            Represents prediction of wine quality.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Apply the layers defined in __init__() to input features X\n",
    "        return self.model(X)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels=20531, class_num=2):\n",
    "        \"\"\"\n",
    "        Initializes model layers.\n",
    "        :param input_channels: The number of features of each sample.\n",
    "        :param class_num: The number of categories.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_channels, 16, 3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 32, 3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, 3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(256, class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Applies the layers defined in __init__() to input features X.\n",
    "        :param X: 4D torch tensor of shape [n, 1, 8, 8], where n is batch size.\n",
    "            Represents a batch of 8 * 8 gray scale images.\n",
    "        :return: 2D torch tensor of shape [n, 10], where n is batch size.\n",
    "            Represents logits of different categories.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.model(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_func, optimizer, num_epoch, correct_num_func=None, print_info=True):\n",
    "    \"\"\"\n",
    "    Trains the model for `num_epoch` epochs.\n",
    "    :param model: A deep model.\n",
    "    :param dataloader: Dataloader of the training set. Contains the training data equivalent to ((Xi, Yi)),\n",
    "        where (Xi, Yi) is a batch of data.\n",
    "        X: 2D torch tensor for UCI wine and 4D torch tensor for MNIST.\n",
    "        X: 2D torch tensor for UCI wine and 1D torch tensor for MNIST, containing the corresponding labels\n",
    "            for each example.\n",
    "        Refer to the Data Format section in the handout for more information.\n",
    "    :param loss_func: An MSE loss function for UCI wine and a cross entropy loss for MNIST.\n",
    "    :param optimizer: An optimizer instance from torch.optim.\n",
    "    :param num_epoch: The number of epochs we train our network.\n",
    "    :param correct_num_func: A function to calculate how many samples are correctly classified.\n",
    "        You need to implement correct_predict_num() below.\n",
    "        To train the CNN model, we also want to calculate the classification accuracy in addition to loss.\n",
    "    :param print_info: If True, print the average loss (and accuracy, if applicable) after each epoch.\n",
    "    :return:\n",
    "        epoch_average_losses: A list of average loss after each epoch.\n",
    "            Note: different from HW10, we will return average losses instead of total losses.\n",
    "        epoch_accuracies: A list of accuracy values after each epoch. This is applicable when training on MNIST.\n",
    "    \"\"\"\n",
    "\n",
    "    average_loss = []\n",
    "    accuracys = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        # Initializing variables\n",
    "\n",
    "        # Sum of losses in an epoch. Will be used to calculate average loss.\n",
    "        # The reason we are using (epoch_loss_sum / #samples in each batch) to calculate the\n",
    "        # average loss is that the number of samples in the last batch may be fewer than your batch_size.\n",
    "        epoch_loss_sum = 0\n",
    "\n",
    "        # Sum of the number of correct predictions. Will be used to calculate average accuracy for CNN.\n",
    "        epoch_correct_num = 0\n",
    "\n",
    "        # TODO: Iterate through batches. HINT: for X, Y in dataloader:\n",
    "        for X, Y in dataloader:\n",
    "            # TODO: Run a forward pass and get model output\n",
    "            output = model.forward(X)\n",
    "            # TODO: Set all gradients to zero by calling optimizer.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            # TODO: Calculate loss of this batch\n",
    "            loss = loss_func(output, Y)\n",
    "\n",
    "            # TODO: Run a backward pass by calling loss.backward(),\n",
    "            #  where loss is the output of the loss function.\n",
    "\n",
    "            loss.backward()\n",
    "            # TODO: Update parameters by calling optimizer.step()\n",
    "            optimizer.step()\n",
    "            # TODO: Increase epoch_loss_sum by (loss * #samples in the current batch)\n",
    "            #  Use loss.item() to get the python scalar of loss value because the output of\n",
    "            #   loss function also contains gradient information, which takes a lot of memory.\n",
    "            #  Use X.shape[0] to get the number of samples in the current batch.\n",
    "            epoch_loss_sum += loss.item() * X.shape[0]\n",
    "            \n",
    "            # TODO: Calculate the number of correct predictions for CNN on MNIST\n",
    "            num_correct = correct_predict_num(output, Y)\n",
    "\n",
    "            # TODO: When correct_num_func is not None,\n",
    "            #  increase epoch_correct_num by #correct predictions in the current batch\n",
    "            if correct_num_func != None:\n",
    "                epoch_correct_num += num_correct\n",
    "\n",
    "        # TODO: Append the average loss of the current epoch to your list.\n",
    "        #  You can get the number of training samples by len(dataloader.dataset)\n",
    "        average_loss.append(epoch_loss_sum / len(dataloader.dataset))\n",
    "\n",
    "        # TODO: When correct_num_func is not None,\n",
    "        #  calculate average accuracy for CNN on MNIST if correct_num_func:\n",
    "        #  Append the average accuracy of the current epoch to your list.\n",
    "        #  You can get the number of training samples by len(dataloader.dataset)\n",
    "        if correct_num_func != None:\n",
    "            accuracys.append(epoch_correct_num / len(dataloader.dataset))\n",
    "\n",
    "        # Print the loss after every epoch. Print accuracies if specified\n",
    "        if print_info:\n",
    "            print('Epoch: {} | Loss: {:.4f} '.format(epoch, epoch_loss_sum / len(dataloader.dataset)), end=\"\")\n",
    "            if correct_num_func:\n",
    "                print('Accuracy: {:.4f}%'.format(epoch_correct_num / len(dataloader.dataset) * 100), end=\"\")\n",
    "            print()\n",
    "\n",
    "    # TODO: When correct_num_func is None, only return a list of average losses.\n",
    "    #  When correct_num_func is not None, return a list of average losses and a list of accuracies.\n",
    "    if correct_num_func == None:\n",
    "        return average_loss\n",
    "    else:\n",
    "        return average_loss, accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, loss_func, correct_num_func=None):\n",
    "    \"\"\"\n",
    "    Tests the model.\n",
    "    :param model: A deep model.\n",
    "    :param dataloader: Dataloader of the testing set. Contains the testing data equivalent to ((Xi, Yi)),\n",
    "        where (Xi, Yi) is a batch of data.\n",
    "        X: 2D torch tensor for UCI wine and 4D torch tensor for MNIST.\n",
    "        X: 2D torch tensor for UCI wine and 1D torch tensor for MNIST, containing the corresponding labels\n",
    "            for each example.\n",
    "        Refer to the Data Format section in the handout for more information.\n",
    "    :param loss_func: An MSE loss function for UCI wine and a cross entropy loss for MNIST.\n",
    "    :param correct_num_func: A function to calculate how many samples are correctly classified.\n",
    "        You need to implement correct_predict_num() below.\n",
    "        To test the CNN model, we also want to calculate the classification accuracy in addition to loss.\n",
    "    :return:\n",
    "        Average loss.\n",
    "        Average accuracy. This is applicable when testing on MNIST.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    :param dataloader: Contains the training data equivalent to ((X, Y))\n",
    "        :param X: 2D Numpy array where each row contains an example\n",
    "        :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "    :param loss_func: An MSE loss function from the Pytorch Library\n",
    "    :return: epoch loss and accuracies to be graphed\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Initalizing variables\n",
    "        # Initialize sum of losses in an epoch. Will be used to calculate average loss.\n",
    "        # Initialize sum of the number of correct predictions. Will be used to calculate average accuracy for CNN.\n",
    "    sum_loss = 0\n",
    "    sum_correct = 0\n",
    "    # TODO: Tell the model we are in the testing phase. HINT: model.eval()\n",
    "    model.eval()\n",
    "    # TODO: During testing, we don't need to calculate gradients. HINT: use 'with torch.no_grad():'\n",
    "    with torch.no_grad():\n",
    "        # TODO: Iterate through batches.\n",
    "        for X, Y in dataloader:\n",
    "            # TODO: Run a forward pass and get model output\n",
    "            output = model.forward(X)\n",
    "            # TODO: Calculate loss of this batch\n",
    "            loss = loss_func(output, Y)\n",
    "            # TODO: Increase loss sum by (loss * #samples in the current batch)\n",
    "            #  Use loss.item() to get the python scalar of loss value.\n",
    "            #  Use X.shape[0] to get the number of samples in the current batch.\n",
    "            sum_loss += loss.item() * X.shape[0]\n",
    "            # TODO: When correct_num_func is not None, calculate the number of correct predictions for CNN on MNIST\n",
    "            #  Increase the total number of correct predictions by #correct predictions in the current batch\n",
    "            if correct_num_func != None:\n",
    "                sum_correct += correct_predict_num(output, Y) \n",
    "    # TODO: When correct_num_func is None, return average loss.\n",
    "    #  When correct_num_func is not None, return average loss and accuracy.\n",
    "    if correct_num_func == None:\n",
    "        return sum_loss / len(dataloader.dataset)\n",
    "    else:\n",
    "        return sum_loss / len(dataloader.dataset), sum_correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses):\n",
    "    \"\"\"\n",
    "    Uses Matplotlib to visualize loss per batch.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    x = np.arange(1, len(losses) + 1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.plot(x, losses)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predict_num(logit, target):\n",
    "    \"\"\"\n",
    "    Returns the number of correct predictions.\n",
    "    :param logit: 2D torch tensor of shape [n, class_num], where\n",
    "        n is the number of samples, and class_num is the number of classes (10 for MNIST).\n",
    "        Represents the output of CNN model.\n",
    "    :param target: 1D torch tensor of shape [n],  where n is the number of samples.\n",
    "        Represents the ground truth categories of images.\n",
    "    :return: A python scalar. The number of correct predictions.\n",
    "    \"\"\"\n",
    "    # TODO: Calculate the number of correct predictions.\n",
    "    # HINT: torch.sum, torch.argmax\n",
    "    # You may need .long() to convert a torch tensor to LongTensor.\n",
    "    # Use .item() to convert a torch tensor of size 1 to python scalar.\n",
    "    return torch.sum(torch.argmax(logit, dim=1) == target).item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (426, 20531) (426,)\n",
      "Dataset (107, 20531) (107,)\n",
      "Epoch: 0 | Loss: 33330.0113 \n",
      "Epoch: 1 | Loss: 18609.4583 \n",
      "Epoch: 2 | Loss: 4295.1870 \n",
      "Epoch: 3 | Loss: 6719.8838 \n",
      "Epoch: 4 | Loss: 2912.6306 \n",
      "Epoch: 5 | Loss: 6609.8569 \n",
      "Epoch: 6 | Loss: 4738.8068 \n",
      "Epoch: 7 | Loss: 5951.1153 \n",
      "Epoch: 8 | Loss: 3808.2294 \n",
      "Epoch: 9 | Loss: 3345.8788 \n",
      "Epoch: 10 | Loss: 2306.0512 \n",
      "Epoch: 11 | Loss: 759.4360 \n",
      "Epoch: 12 | Loss: 720.9271 \n",
      "Epoch: 13 | Loss: 502.8049 \n",
      "Epoch: 14 | Loss: 512.6524 \n",
      "Epoch: 15 | Loss: 375.8871 \n",
      "Epoch: 16 | Loss: 2185.8233 \n",
      "Epoch: 17 | Loss: 1427.1879 \n",
      "Epoch: 18 | Loss: 568.8564 \n",
      "Epoch: 19 | Loss: 473.7797 \n",
      "Epoch: 20 | Loss: 239.9170 \n",
      "Epoch: 21 | Loss: 242.9856 \n",
      "Epoch: 22 | Loss: 132.5957 \n",
      "Epoch: 23 | Loss: 101.7813 \n",
      "Epoch: 24 | Loss: 153.5537 \n",
      "Average Training Loss: (189.92119687935556, 53.72300469483568)\n",
      "Average Testing Loss: (3687.3639931366824, 43.77570093457944)\n"
     ]
    }
   ],
   "source": [
    "def test_one_layer(test_size=0.2):\n",
    "    \"\"\"\n",
    "    Tests OneLayerNN\n",
    "    :param test_size: The ratio of test set\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = 64  # batch size\n",
    "    num_epoch = 25  # number of training epochs\n",
    "    learning_rate = 0.01  # learning rate\n",
    "\n",
    "    dataloader_train, dataloader_test = get_data_loader(batch_size=batch_size, test_size=test_size)\n",
    "\n",
    "    model = OneLayerNN(input_features=20531)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    losses = train(model, dataloader_train, loss_func, optimizer, num_epoch)\n",
    "\n",
    "    loss_train = test(model, dataloader_train, loss_func, correct_num_func=correct_predict_num)\n",
    "    loss_test = test(model, dataloader_test, loss_func, correct_num_func=correct_predict_num)\n",
    "    print('Average Training Loss:', loss_train)\n",
    "    print('Average Testing Loss:', loss_test)\n",
    "\n",
    "test_one_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (426, 20531) (426,)\n",
      "Dataset (107, 20531) (107,)\n",
      "Epoch: 0 | Loss: 6145.0759 \n",
      "Epoch: 1 | Loss: 275.0334 \n",
      "Epoch: 2 | Loss: 0.6884 \n",
      "Epoch: 3 | Loss: 0.6864 \n",
      "Epoch: 4 | Loss: 0.6842 \n",
      "Epoch: 5 | Loss: 0.6820 \n",
      "Epoch: 6 | Loss: 0.6797 \n",
      "Epoch: 7 | Loss: 0.6773 \n",
      "Epoch: 8 | Loss: 0.6750 \n",
      "Epoch: 9 | Loss: 0.6727 \n",
      "Epoch: 10 | Loss: 0.6705 \n",
      "Epoch: 11 | Loss: 0.6681 \n",
      "Epoch: 12 | Loss: 0.6659 \n",
      "Epoch: 13 | Loss: 0.6636 \n",
      "Epoch: 14 | Loss: 0.6613 \n",
      "Epoch: 15 | Loss: 0.6591 \n",
      "Epoch: 16 | Loss: 0.6568 \n",
      "Epoch: 17 | Loss: 0.6546 \n",
      "Epoch: 18 | Loss: 0.6524 \n",
      "Epoch: 19 | Loss: 0.6502 \n",
      "Epoch: 20 | Loss: 0.6479 \n",
      "Epoch: 21 | Loss: 0.6459 \n",
      "Epoch: 22 | Loss: 0.6437 \n",
      "Epoch: 23 | Loss: 0.6415 \n",
      "Epoch: 24 | Loss: 0.6394 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.6381350078493216\n",
      "Average Testing Loss: (1.9630104587456891, 45.76635514018692)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.9630104587456891, 45.76635514018692)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_two_layer(test_size=0.2):\n",
    "    \"\"\"\n",
    "    Tests OneLayerNN\n",
    "    :param test_size: The ratio of test set\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = 64  # batch size\n",
    "    num_epoch = 25  # number of training epochs\n",
    "    learning_rate = 0.001  # learning rate\n",
    "\n",
    "    dataloader_train, dataloader_test = get_data_loader(batch_size=batch_size, test_size=test_size)\n",
    "\n",
    "    model = TwoLayerNN(input_features=20531)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "    losses = train(model, dataloader_train, loss_func, optimizer, num_epoch)\n",
    "\n",
    "    visualize_loss(losses)\n",
    "\n",
    "    loss_train = test(model, dataloader_train, loss_func)\n",
    "    loss_test = test(model, dataloader_test, loss_func, correct_num_func=correct_predict_num)\n",
    "    print('Average Training Loss:', loss_train)\n",
    "    print('Average Testing Loss:', loss_test)\n",
    "    return loss_test\n",
    "test_two_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (426, 20531) (426,)\n",
      "Dataset (107, 20531) (107,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "X = np.load('processed_mrna_data.npy')\n",
    "Y = np.load('processed_recurrence_data.npy')\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "Y = Y.astype(np.float32)\n",
    "\n",
    "\n",
    "    # Split data into training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "dataset_train = Data(X_train, Y_train)\n",
    "dataset_test = Data(X_test, Y_test)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=64)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(20531, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            print(pred)\n",
    "            print(y)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 45.624237  [   64/  426]\n",
      "tensor([[-103.9876],\n",
      "        [-115.3512],\n",
      "        [-147.6031],\n",
      "        [-113.7361],\n",
      "        [-134.0147],\n",
      "        [-109.4229],\n",
      "        [-142.4927],\n",
      "        [-168.2553],\n",
      "        [ -85.2652],\n",
      "        [-143.9309],\n",
      "        [-146.9219],\n",
      "        [-195.0726],\n",
      "        [-195.8924],\n",
      "        [-137.4620],\n",
      "        [-144.8747],\n",
      "        [-103.5915],\n",
      "        [-140.7576],\n",
      "        [-134.0744],\n",
      "        [-126.7491],\n",
      "        [-144.5330],\n",
      "        [-112.1868],\n",
      "        [-110.8455],\n",
      "        [-148.6163],\n",
      "        [-134.3767],\n",
      "        [ -95.8749],\n",
      "        [-122.6508],\n",
      "        [ -95.8655],\n",
      "        [-104.6213],\n",
      "        [-127.5361],\n",
      "        [-123.0863],\n",
      "        [-110.8278],\n",
      "        [-117.1459],\n",
      "        [-119.2459],\n",
      "        [-102.5132],\n",
      "        [-106.6486],\n",
      "        [-119.8985],\n",
      "        [-140.7439],\n",
      "        [-136.3804],\n",
      "        [-116.3578],\n",
      "        [-118.7969],\n",
      "        [-111.9806],\n",
      "        [-125.1052],\n",
      "        [-147.9725],\n",
      "        [-101.7828],\n",
      "        [-130.2022],\n",
      "        [-137.5759],\n",
      "        [-178.0534],\n",
      "        [-116.2804],\n",
      "        [ -87.4306],\n",
      "        [-128.9955],\n",
      "        [-125.0611],\n",
      "        [-151.3206],\n",
      "        [-139.7977],\n",
      "        [-182.0165],\n",
      "        [-106.0784],\n",
      "        [-125.7392],\n",
      "        [-155.8159],\n",
      "        [-128.2407],\n",
      "        [-104.6832],\n",
      "        [-179.0416],\n",
      "        [-237.6996],\n",
      "        [-116.5526],\n",
      "        [-123.9546],\n",
      "        [-141.7433]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "tensor([[ -96.3544],\n",
      "        [-111.6586],\n",
      "        [-105.7081],\n",
      "        [-141.5787],\n",
      "        [-121.6313],\n",
      "        [-119.9504],\n",
      "        [-133.5951],\n",
      "        [-150.7303],\n",
      "        [ -96.4768],\n",
      "        [-119.8605],\n",
      "        [-129.6202],\n",
      "        [-143.6837],\n",
      "        [-111.9142],\n",
      "        [-139.1083],\n",
      "        [-135.9616],\n",
      "        [-148.7188],\n",
      "        [-119.2699],\n",
      "        [-107.8292],\n",
      "        [-131.8488],\n",
      "        [-142.6710],\n",
      "        [-122.2685],\n",
      "        [-113.4511],\n",
      "        [-120.8344],\n",
      "        [-124.9367],\n",
      "        [-114.1419],\n",
      "        [-135.4412],\n",
      "        [-170.4660],\n",
      "        [-105.5040],\n",
      "        [-124.6191],\n",
      "        [-119.8874],\n",
      "        [-122.9029],\n",
      "        [-156.8515],\n",
      "        [-122.5243],\n",
      "        [ -93.2521],\n",
      "        [-136.4177],\n",
      "        [-128.3678],\n",
      "        [-120.5565],\n",
      "        [ -91.9159],\n",
      "        [-122.8999],\n",
      "        [-133.9946],\n",
      "        [-111.8782],\n",
      "        [-127.2978],\n",
      "        [-132.5275]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Test Error: \n",
      " Accuracy: 4597.2%, Avg loss: 21.178883 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 14.672967  [   64/  426]\n",
      "tensor([[-112.4229],\n",
      "        [-109.9534],\n",
      "        [ -87.1573],\n",
      "        [-108.3445],\n",
      "        [-103.8996],\n",
      "        [-108.8938],\n",
      "        [-107.9961],\n",
      "        [ -86.1288],\n",
      "        [-118.3756],\n",
      "        [-103.5947],\n",
      "        [-103.0946],\n",
      "        [-108.0286],\n",
      "        [ -91.5523],\n",
      "        [-111.6966],\n",
      "        [-112.1977],\n",
      "        [-109.1186],\n",
      "        [-119.8995],\n",
      "        [-124.0499],\n",
      "        [-115.2726],\n",
      "        [-116.3764],\n",
      "        [-114.4165],\n",
      "        [-114.3523],\n",
      "        [-124.7121],\n",
      "        [-106.9355],\n",
      "        [-110.4107],\n",
      "        [-111.4344],\n",
      "        [-118.8863],\n",
      "        [ -99.7796],\n",
      "        [-109.6779],\n",
      "        [-106.5697],\n",
      "        [-144.2786],\n",
      "        [-108.8140],\n",
      "        [-128.9244],\n",
      "        [-102.0195],\n",
      "        [-125.0443],\n",
      "        [-113.0594],\n",
      "        [-117.3750],\n",
      "        [-116.5706],\n",
      "        [-118.6560],\n",
      "        [-125.0661],\n",
      "        [-104.6477],\n",
      "        [-104.0255],\n",
      "        [-102.1779],\n",
      "        [ -98.6697],\n",
      "        [-119.8098],\n",
      "        [-110.5942],\n",
      "        [ -88.5927],\n",
      "        [-107.1027],\n",
      "        [-114.6205],\n",
      "        [-111.0007],\n",
      "        [-109.2776],\n",
      "        [-102.0241],\n",
      "        [-108.7162],\n",
      "        [ -70.8722],\n",
      "        [-105.3838],\n",
      "        [-107.6688],\n",
      "        [-101.2943],\n",
      "        [-100.1451],\n",
      "        [-101.2138],\n",
      "        [ -91.8814],\n",
      "        [-106.5632],\n",
      "        [-139.3433],\n",
      "        [-113.8678],\n",
      "        [ -98.5670]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "tensor([[-114.0894],\n",
      "        [-103.2759],\n",
      "        [-115.0321],\n",
      "        [-109.0560],\n",
      "        [-112.3122],\n",
      "        [-107.3080],\n",
      "        [-105.1632],\n",
      "        [-111.6442],\n",
      "        [-104.8328],\n",
      "        [-103.2565],\n",
      "        [-105.2019],\n",
      "        [-102.5844],\n",
      "        [-112.3967],\n",
      "        [-152.0396],\n",
      "        [-105.5530],\n",
      "        [-105.5956],\n",
      "        [-100.7551],\n",
      "        [-108.6360],\n",
      "        [-105.2339],\n",
      "        [-154.3434],\n",
      "        [-118.1985],\n",
      "        [-103.8065],\n",
      "        [-108.0889],\n",
      "        [-105.6430],\n",
      "        [-108.7569],\n",
      "        [ -93.3211],\n",
      "        [-108.9758],\n",
      "        [-104.6039],\n",
      "        [-104.5313],\n",
      "        [-104.7731],\n",
      "        [-109.5814],\n",
      "        [-105.2669],\n",
      "        [-103.1225],\n",
      "        [-116.7573],\n",
      "        [-106.5384],\n",
      "        [ -98.4422],\n",
      "        [-104.5124],\n",
      "        [-111.4962],\n",
      "        [-116.5042],\n",
      "        [-104.8469],\n",
      "        [-113.6398],\n",
      "        [ -97.8876],\n",
      "        [ -99.8965]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Test Error: \n",
      " Accuracy: 4597.2%, Avg loss: 17.231513 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 8.915719  [   64/  426]\n",
      "tensor([[ -3.5770],\n",
      "        [ -5.3126],\n",
      "        [  3.7618],\n",
      "        [ -5.2545],\n",
      "        [  1.1618],\n",
      "        [ -5.2059],\n",
      "        [ -4.9669],\n",
      "        [ 13.9035],\n",
      "        [ -1.0526],\n",
      "        [ -4.6713],\n",
      "        [ -4.8003],\n",
      "        [-13.5590],\n",
      "        [-28.9598],\n",
      "        [ -6.0093],\n",
      "        [ -5.0195],\n",
      "        [ -5.9604],\n",
      "        [ -5.4109],\n",
      "        [ -6.1743],\n",
      "        [ -3.1151],\n",
      "        [ -4.8162],\n",
      "        [ -4.8883],\n",
      "        [ -6.9234],\n",
      "        [  0.2010],\n",
      "        [ -5.4908],\n",
      "        [ -4.3589],\n",
      "        [ -5.2334],\n",
      "        [ -3.6718],\n",
      "        [ -5.4292],\n",
      "        [ -4.8186],\n",
      "        [ -4.4373],\n",
      "        [ -0.3431],\n",
      "        [ -4.7829],\n",
      "        [  0.7356],\n",
      "        [ -5.6709],\n",
      "        [ -4.5673],\n",
      "        [ -3.2944],\n",
      "        [ -5.1189],\n",
      "        [ -3.3359],\n",
      "        [ -3.4777],\n",
      "        [ -2.4998],\n",
      "        [ -4.8088],\n",
      "        [ -5.5837],\n",
      "        [ -2.3901],\n",
      "        [ -5.0910],\n",
      "        [ -5.7591],\n",
      "        [ -4.6527],\n",
      "        [ 18.5635],\n",
      "        [ -4.8762],\n",
      "        [ -5.5844],\n",
      "        [ -3.5116],\n",
      "        [ -4.8788],\n",
      "        [  0.4361],\n",
      "        [ -4.5202],\n",
      "        [-32.5451],\n",
      "        [  1.2576],\n",
      "        [ -5.7905],\n",
      "        [  6.1834],\n",
      "        [ -5.4967],\n",
      "        [ -5.1529],\n",
      "        [ 13.7653],\n",
      "        [-76.7335],\n",
      "        [ -3.9697],\n",
      "        [ -4.9113],\n",
      "        [ -2.2022]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "tensor([[-5.2350],\n",
      "        [-5.0717],\n",
      "        [-5.7037],\n",
      "        [-4.9006],\n",
      "        [-6.0521],\n",
      "        [-5.9933],\n",
      "        [-4.3472],\n",
      "        [-4.1889],\n",
      "        [-2.6231],\n",
      "        [-4.9813],\n",
      "        [-4.5387],\n",
      "        [-2.1607],\n",
      "        [-3.6052],\n",
      "        [-7.2526],\n",
      "        [-5.4642],\n",
      "        [-2.8728],\n",
      "        [-5.0771],\n",
      "        [-5.9310],\n",
      "        [-4.0116],\n",
      "        [-6.7821],\n",
      "        [-3.4983],\n",
      "        [-4.7103],\n",
      "        [-4.6400],\n",
      "        [-5.1522],\n",
      "        [-6.1438],\n",
      "        [ 6.1909],\n",
      "        [-1.3997],\n",
      "        [-4.5969],\n",
      "        [-5.9048],\n",
      "        [-5.2228],\n",
      "        [-5.5481],\n",
      "        [ 2.7469],\n",
      "        [-5.4143],\n",
      "        [-5.4282],\n",
      "        [-4.4392],\n",
      "        [-5.0530],\n",
      "        [-4.5232],\n",
      "        [-5.4445],\n",
      "        [-6.1611],\n",
      "        [-5.1585],\n",
      "        [-4.2057],\n",
      "        [-4.3785],\n",
      "        [-1.3573]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Test Error: \n",
      " Accuracy: 4597.2%, Avg loss: 1.062286 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.760670  [   64/  426]\n",
      "tensor([[ -1.2297],\n",
      "        [ -0.8350],\n",
      "        [ -7.3754],\n",
      "        [ -1.0146],\n",
      "        [ -1.0861],\n",
      "        [ -0.9938],\n",
      "        [ -3.7497],\n",
      "        [-10.0001],\n",
      "        [ -2.6492],\n",
      "        [ -6.8899],\n",
      "        [ -3.9105],\n",
      "        [-23.4383],\n",
      "        [-23.4795],\n",
      "        [ -0.9854],\n",
      "        [ -2.7655],\n",
      "        [ -1.1199],\n",
      "        [ -3.0929],\n",
      "        [ -1.1624],\n",
      "        [ -1.3971],\n",
      "        [ -2.3390],\n",
      "        [ -0.9370],\n",
      "        [ -0.4903],\n",
      "        [ -0.6523],\n",
      "        [ -1.6509],\n",
      "        [ -0.7570],\n",
      "        [ -1.2731],\n",
      "        [ -0.8165],\n",
      "        [ -0.8046],\n",
      "        [ -0.8097],\n",
      "        [ -1.7333],\n",
      "        [ -2.4681],\n",
      "        [ -0.8374],\n",
      "        [ -2.0994],\n",
      "        [ -0.9551],\n",
      "        [ -1.1527],\n",
      "        [ -0.7658],\n",
      "        [ -0.9388],\n",
      "        [ -0.8855],\n",
      "        [ -0.8931],\n",
      "        [ -1.2300],\n",
      "        [ -0.7362],\n",
      "        [ -0.3757],\n",
      "        [ -7.8430],\n",
      "        [ -0.8771],\n",
      "        [ -2.8145],\n",
      "        [ -1.8133],\n",
      "        [-14.2063],\n",
      "        [ -0.9364],\n",
      "        [ -1.1483],\n",
      "        [ -2.3986],\n",
      "        [ -4.3613],\n",
      "        [ -2.3029],\n",
      "        [-10.7229],\n",
      "        [ -5.4619],\n",
      "        [ -1.4180],\n",
      "        [ -1.1953],\n",
      "        [ -7.4786],\n",
      "        [ -1.0650],\n",
      "        [ -1.0317],\n",
      "        [-10.3467],\n",
      "        [-25.5230],\n",
      "        [ -0.9578],\n",
      "        [ -1.1861],\n",
      "        [ -2.8471]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "tensor([[ -0.9403],\n",
      "        [ -0.8667],\n",
      "        [ -1.1210],\n",
      "        [ -1.9532],\n",
      "        [ -1.0112],\n",
      "        [ -0.9269],\n",
      "        [ -6.7161],\n",
      "        [ -2.1619],\n",
      "        [ -1.2818],\n",
      "        [ -3.1579],\n",
      "        [ -0.8657],\n",
      "        [ -3.3710],\n",
      "        [ -0.8416],\n",
      "        [ -1.0710],\n",
      "        [ -1.1409],\n",
      "        [ -1.0227],\n",
      "        [ -0.8815],\n",
      "        [ -1.2099],\n",
      "        [ -5.1340],\n",
      "        [ -3.5652],\n",
      "        [ -0.4975],\n",
      "        [ -1.1565],\n",
      "        [ -2.4339],\n",
      "        [ -5.6083],\n",
      "        [ -1.0257],\n",
      "        [-12.5606],\n",
      "        [-12.2018],\n",
      "        [ -0.8675],\n",
      "        [ -0.9228],\n",
      "        [ -0.7847],\n",
      "        [ -1.7686],\n",
      "        [ -7.7117],\n",
      "        [ -1.0575],\n",
      "        [ -1.0180],\n",
      "        [ -1.8921],\n",
      "        [ -2.1477],\n",
      "        [ -2.1216],\n",
      "        [ -1.1792],\n",
      "        [ -1.2133],\n",
      "        [ -4.8669],\n",
      "        [ -0.3475],\n",
      "        [ -3.0192],\n",
      "        [ -2.5198]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Test Error: \n",
      " Accuracy: 4597.2%, Avg loss: 0.641111 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.261606  [   64/  426]\n",
      "tensor([[ -9.2202],\n",
      "        [ -1.1426],\n",
      "        [ -0.0737],\n",
      "        [ -0.7900],\n",
      "        [-10.6756],\n",
      "        [ -3.6882],\n",
      "        [  1.2148],\n",
      "        [  0.2544],\n",
      "        [-13.6529],\n",
      "        [  0.8109],\n",
      "        [  0.8894],\n",
      "        [  3.9593],\n",
      "        [  3.9895],\n",
      "        [  1.5603],\n",
      "        [  1.4831],\n",
      "        [  1.8423],\n",
      "        [  1.3395],\n",
      "        [ -8.2701],\n",
      "        [  2.4489],\n",
      "        [  1.2633],\n",
      "        [ -0.3522],\n",
      "        [-19.5358],\n",
      "        [  0.2981],\n",
      "        [  1.2410],\n",
      "        [  1.2315],\n",
      "        [  2.0494],\n",
      "        [  1.2300],\n",
      "        [ -1.9045],\n",
      "        [  1.3091],\n",
      "        [  0.9943],\n",
      "        [-10.2000],\n",
      "        [  1.2797],\n",
      "        [ -4.2556],\n",
      "        [ -4.4505],\n",
      "        [  1.5824],\n",
      "        [  1.0723],\n",
      "        [ -9.3301],\n",
      "        [  0.7086],\n",
      "        [  0.2086],\n",
      "        [ -9.3558],\n",
      "        [  0.2373],\n",
      "        [-10.7334],\n",
      "        [  0.9664],\n",
      "        [ -4.0318],\n",
      "        [  1.1664],\n",
      "        [  1.0860],\n",
      "        [  1.6300],\n",
      "        [ -2.3199],\n",
      "        [-18.3820],\n",
      "        [  0.7539],\n",
      "        [  1.4825],\n",
      "        [  1.7582],\n",
      "        [  0.8697],\n",
      "        [ -1.9084],\n",
      "        [  2.6191],\n",
      "        [  2.0790],\n",
      "        [  2.1471],\n",
      "        [  1.5815],\n",
      "        [  1.3415],\n",
      "        [  0.2561],\n",
      "        [ 23.6920],\n",
      "        [  1.0352],\n",
      "        [  1.4937],\n",
      "        [  1.4085]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "tensor([[ -1.3051],\n",
      "        [  1.3909],\n",
      "        [ -4.5421],\n",
      "        [  0.8851],\n",
      "        [  0.2732],\n",
      "        [  0.9133],\n",
      "        [  1.3652],\n",
      "        [  0.6272],\n",
      "        [  2.0995],\n",
      "        [  1.6888],\n",
      "        [  1.3601],\n",
      "        [  1.7099],\n",
      "        [ -2.6581],\n",
      "        [ -1.1668],\n",
      "        [  1.5686],\n",
      "        [ -2.8004],\n",
      "        [ -2.5080],\n",
      "        [  1.9558],\n",
      "        [  0.8428],\n",
      "        [  1.6142],\n",
      "        [ -2.6144],\n",
      "        [  1.8601],\n",
      "        [  1.3247],\n",
      "        [  1.3072],\n",
      "        [ -5.4268],\n",
      "        [  1.3142],\n",
      "        [  1.0455],\n",
      "        [ -1.5136],\n",
      "        [ -0.7887],\n",
      "        [ -0.4464],\n",
      "        [  1.2023],\n",
      "        [  1.8206],\n",
      "        [  1.5819],\n",
      "        [ -9.2635],\n",
      "        [  1.0520],\n",
      "        [  1.2284],\n",
      "        [  1.2705],\n",
      "        [-16.9719],\n",
      "        [  1.9100],\n",
      "        [  1.2818],\n",
      "        [-10.0710],\n",
      "        [  1.5072],\n",
      "        [  1.9465]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Test Error: \n",
      " Accuracy: 4597.2%, Avg loss: 1.346110 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(dataloader_train, model, loss_fn, optimizer)\n",
    "    test_loop(dataloader_test, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
